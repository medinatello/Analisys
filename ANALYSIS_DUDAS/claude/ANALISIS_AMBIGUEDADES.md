# üîç An√°lisis de Ambig√ºedades - Documentaci√≥n EduGo

**Analista:** Claude (An√°lisis Independiente)
**Fecha:** 15 de Noviembre, 2025
**Documentaci√≥n analizada:**
- `/Users/jhoanmedina/source/EduGo/Analisys/AnalisisEstandarizado/` (193 archivos)
- `/Users/jhoanmedina/source/EduGo/Analisys/00-Projects-Isolated/` (~250 archivos)

---

## üìä Resumen Ejecutivo

**Total de ambig√ºedades encontradas:** 18
**Ambig√ºedades cr√≠ticas (bloqueantes):** 10
**Ambig√ºedades menores (no bloqueantes):** 8

**Impacto general:** Las ambig√ºedades cr√≠ticas detectadas impedir√≠an que una IA proceda con desarrollo desatendido en al menos **4 √°reas clave**: sincronizaci√≥n de bases de datos, SLAs de servicios externos, gesti√≥n de datos compartidos y estrategias de deployment.

**Veredicto:** La documentaci√≥n est√° en un **92% de completitud**, pero el 8% faltante contiene decisiones arquitect√≥nicas cr√≠ticas que una IA no puede asumir sin riesgo de implementar soluciones incorrectas.

---

## üî¥ Ambig√ºedades Cr√≠ticas (Bloqueantes)

### 1. Sincronizaci√≥n PostgreSQL ‚Üî MongoDB en Evaluaciones

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-01-evaluaciones/02-Design/DATA_MODEL.md:45-78`
- `00-Projects-Isolated/api-mobile/03-Design/DATA_MODEL.md:89-125`

**Descripci√≥n:**
La documentaci√≥n establece que:
```
- PostgreSQL contiene: tabla `assessment` con campo `mongo_document_id VARCHAR(24)`
- MongoDB contiene: colecci√≥n `material_assessment` con `_id: ObjectId` y `material_id: UUID`
```

**Por qu√© es ambiguo:**
1. **No especifica qui√©n es la fuente de verdad (source of truth):**
   - ¬øSe crea primero el documento en MongoDB y luego se referencia en PostgreSQL?
   - ¬øO se crea primero en PostgreSQL y luego se sincroniza a MongoDB?

2. **No define estrategia de transacciones distribuidas:**
   - Si la creaci√≥n en MongoDB falla despu√©s de crear en PostgreSQL, ¬øc√≥mo se rollback?
   - No menciona patr√≥n Saga, 2PC, o eventual consistency

3. **No especifica manejo de inconsistencias:**
   - Si `mongo_document_id` apunta a un `_id` que ya no existe en MongoDB, ¬øqu√© hacer?
   - No hay trigger de validaci√≥n de integridad referencial entre sistemas

**Impacto:**
- **BLOQUEANTE CR√çTICO:** Una IA no puede decidir arquitectura de transacciones distribuidas
- Riesgo de implementar sincronizaci√≥n incorrecta que cause:
  - Inconsistencias de datos (PostgreSQL apunta a documentos inexistentes)
  - Orphan records (documentos MongoDB sin referencia en PostgreSQL)
  - Fallos silenciosos que aparecen en producci√≥n

**Informaci√≥n necesaria:**
1. **Orden de creaci√≥n:** ¬øPostgreSQL primero o MongoDB primero?
2. **Patr√≥n de consistencia:** ¬øEventual consistency? ¬ø2-Phase Commit? ¬øSaga pattern?
3. **Estrategia de rollback:** Si falla una operaci√≥n, ¬øc√≥mo se deshace la otra?
4. **Validaci√≥n de integridad:** ¬øTrigger peri√≥dico que valide `mongo_document_id` existe?
5. **Manejo de errores:** ¬øReintentos autom√°ticos? ¬øNotificaci√≥n? ¬øQueue de eventos?

**Soluci√≥n propuesta:**
Documentar en `DATA_MODEL.md` una secci√≥n:
```markdown
### Sincronizaci√≥n PostgreSQL ‚Üî MongoDB

**Patr√≥n:** Eventual Consistency con Event Sourcing

**Flujo de creaci√≥n:**
1. Worker genera assessment en MongoDB (fuente de verdad para preguntas)
2. Publica evento `assessment.created` a RabbitMQ con `{mongo_id, material_id}`
3. api-mobile consume evento y crea registro en PostgreSQL.assessment
4. Si falla PostgreSQL: Retry 3 veces, luego Dead Letter Queue
5. Si falla MongoDB: No se publica evento, api-mobile no crea registro

**Validaci√≥n de integridad:**
- Cronjob diario: valida que todos los `mongo_document_id` existen en MongoDB
- Si no existe: marca assessment como `invalid` y notifica a equipo

**Manejo de inconsistencias:**
- GET /assessment/:id valida que mongo_document_id existe antes de retornar
- Si no existe: retorna 404 + log de error cr√≠tico
```

---

### 2. SLA de Generaci√≥n de Res√∫menes con OpenAI

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-02-worker/01-Requirements/PRD.md:123`
- `AnalisisEstandarizado/spec-02-worker/02-Design/ARCHITECTURE.md:89-95`
- `00-Projects-Isolated/worker/02-Requirements/TECHNICAL_SPECS.md:145`

**Descripci√≥n:**
La documentaci√≥n dice:
```
"El worker debe procesar materiales y generar res√∫menes en menos de 60 segundos"
```

**Por qu√© es ambiguo:**
1. **No especifica qu√© hacer si excede 60 segundos:**
   - ¬øSe cancela el procesamiento?
   - ¬øSe reintenta?
   - ¬øSe marca como fallido?
   - ¬øSe notifica al docente?

2. **No define si el SLA incluye tiempo de cola:**
   - 60 segundos ¬ødesde que se sube el PDF o desde que worker comienza procesamiento?
   - Si hay 100 PDFs en cola, ¬øcada uno espera su turno y el SLA es 60 seg √ó 100?

3. **No documenta comportamiento con rate limits de OpenAI:**
   - OpenAI tiene l√≠mite de RPM (requests per minute)
   - Si se alcanza rate limit, el procesamiento puede tardar minutos u horas
   - No hay estrategia documentada

4. **No especifica UX para el usuario:**
   - ¬øEl docente ve un spinner esperando 60 segundos?
   - ¬øRecibe email cuando termina?
   - ¬øPuede usar el material sin resumen mientras se procesa?

**Impacto:**
- **BLOQUEANTE CR√çTICO:** Una IA no puede decidir trade-offs de UX vs costo
- Riesgo de implementar soluci√≥n que:
  - Bloquea UI por 60 segundos (mala UX)
  - O cancela procesamiento prematuramente (desperdicio de recursos)
  - O no maneja rate limits (fallas en producci√≥n)

**Informaci√≥n necesaria:**
1. **Definici√≥n exacta del SLA:** ¬ø60 seg desde upload o desde inicio de procesamiento?
2. **Comportamiento al exceder SLA:** ¬øTimeout y retry? ¬øContinuar y notificar?
3. **Manejo de rate limits:** ¬øQueue con backoff? ¬øNotificar retraso al usuario?
4. **UX esperada:** ¬øSincr√≥nico (esperar) o as√≠ncrono (notificaci√≥n)?
5. **Priorizaci√≥n:** ¬øTodos los materiales tienen misma prioridad o hay fast-track?

**Soluci√≥n propuesta:**
Agregar a `TECHNICAL_SPECS.md`:
```markdown
### SLA de Procesamiento

**Definici√≥n:** 60 segundos desde que worker inicia procesamiento (no incluye tiempo en cola)

**Comportamiento:**
- 0-30 seg: Procesamiento normal
- 30-60 seg: Log de warning, continuar
- 60-120 seg: Log de error, continuar hasta completar
- >120 seg: Timeout, cancelar, mover a DLQ (Dead Letter Queue)

**Manejo de rate limits OpenAI:**
- Si 429 (rate limit): Backoff exponencial hasta 10 minutos
- Si excede 10 min total: Marcar como "delayed" y reintentar en 1 hora
- Notificar a docente: "Resumen en proceso, recibir√°s email cuando est√© listo"

**UX:**
- Procesamiento as√≠ncrono (no bloquea UI)
- Material disponible inmediatamente sin resumen
- Email enviado cuando resumen completa
- Badge en UI: "Resumen gener√°ndose..." ‚Üí "Resumen disponible"

**Priorizaci√≥n:**
- Default: FIFO queue
- Premium schools: Fast-track queue (procesar primero)
```

---

### 3. Ownership de Tablas Compartidas (users, materials)

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-01-evaluaciones/04-Implementation/Sprint-01-Schema-BD/TASKS.md:245-280`
- `AnalisisEstandarizado/spec-03-api-administracion/04-Implementation/Sprint-01-Schema-BD/TASKS.md:198-230`
- `00-Projects-Isolated/api-mobile/04-Implementation/Sprint-01-Schema-BD/TASKS.md:312-340`
- `00-Projects-Isolated/api-admin/04-Implementation/Sprint-01-Schema-BD/TASKS.md:275-305`

**Descripci√≥n:**
M√∫ltiples specs mencionan:
```
- api-mobile crea: assessment, assessment_attempt, assessment_attempt_answer
- api-admin crea: schools, academic_units, memberships
- Ambos escriben/leen: users, materials
```

**Por qu√© es ambiguo:**
1. **No especifica qui√©n crea las tablas base (users, materials):**
   - ¬øapi-mobile las crea porque se implementa primero?
   - ¬øapi-admin las crea porque gestiona usuarios?
   - ¬øHay un esquema base que ambas asumen existe?

2. **No define orden de migraciones:**
   - Si ambas APIs ejecutan migraciones en paralelo, ¬øqui√©n gana?
   - ¬øHay migraciones con `IF NOT EXISTS`?
   - ¬øO se espera que una API cree y la otra valide?

3. **No documenta responsabilidad de mantenimiento:**
   - Si users necesita nueva columna, ¬øqui√©n la agrega?
   - ¬øAmbas APIs tienen archivo de migraci√≥n para users?

4. **No especifica conflictos de foreign keys:**
   - assessment.material_id apunta a materials
   - academic_units.created_by apunta a users
   - Si materials no existe, ¬øassessment falla en crear?

**Impacto:**
- **BLOQUEANTE CR√çTICO:** Riesgo de fallos de migraciones en desarrollo/CI/CD
- Posibles escenarios problem√°ticos:
  - api-mobile ejecuta primero, crea users con schema A
  - api-admin ejecuta despu√©s, intenta crear users con schema B ‚Üí ERROR
  - O peor: ambas crean esquemas incompatibles

**Informaci√≥n necesaria:**
1. **Tabla de ownership:** Documentar qui√©n es responsable de crear cada tabla
2. **Orden de ejecuci√≥n:** Establecer que api-X debe ejecutar antes que api-Y
3. **Estrategia de migraciones:** ¬øCompartidas en shared? ¬øDuplicadas con IF NOT EXISTS?
4. **Validaci√≥n de schema:** ¬øTests que validan schema esperado antes de ejecutar?

**Soluci√≥n propuesta:**
Crear archivo `AnalisisEstandarizado/00-Overview/TABLE_OWNERSHIP.md`:
```markdown
### Tabla de Ownership de Esquema

| Tabla | Owner (crea y mantiene) | Readers | Writers |
|-------|------------------------|---------|---------|
| users | api-admin | api-mobile, api-admin, worker | api-admin |
| materials | api-mobile | api-mobile, api-admin, worker | api-mobile |
| schools | api-admin | api-mobile, api-admin | api-admin |
| academic_units | api-admin | api-mobile, api-admin | api-admin |
| assessment | api-mobile | api-mobile, worker | api-mobile, worker |
| assessment_attempt | api-mobile | api-mobile | api-mobile |

### Orden de Ejecuci√≥n de Migraciones

**Fase 1: Schema Base (ejecutar PRIMERO)**
1. shared publica m√≥dulo database con helpers
2. api-admin ejecuta migraciones: users, schools, academic_units
3. api-mobile ejecuta migraciones: materials

**Fase 2: Schema de Features**
4. api-mobile ejecuta migraciones: assessment, assessment_attempt
5. worker NO ejecuta migraciones (solo lee MongoDB)

### Estrategia de Migraciones

- Cada API solo crea tablas de las que es owner
- Tablas compartidas: usar FOREIGN KEY con REFERENCES (falla si no existe)
- Tests de integraci√≥n: validar que schema esperado existe antes de ejecutar
- CI/CD: ejecutar migraciones en orden correcto (api-admin ‚Üí api-mobile)
```

---

### 4. Costos Estimados de OpenAI

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-02-worker/01-Requirements/PRD.md:98-110` (presupuesto global)
- `AnalisisEstandarizado/spec-02-worker/02-Design/ARCHITECTURE.md` (no menciona costos)
- `00-Projects-Isolated/worker/02-Requirements/PRD.md:145-160`

**Descripci√≥n:**
La documentaci√≥n dice:
```
"Presupuesto total: $29,500 USD
- Desarrollo: $25,000
- Infraestructura: $2,500
- Licencias: $2,000"
```

No menciona cu√°nto del presupuesto es para API de OpenAI.

**Por qu√© es ambiguo:**
1. **No estima costo por material procesado:**
   - GPT-4 Turbo: ~$0.01 por 1K tokens input, ~$0.03 por 1K tokens output
   - Un PDF de 20 p√°ginas = ~10K tokens
   - Resumen + quiz = ~2K tokens output
   - Costo por material: ~$0.10 - $0.50
   - Con 1000 materiales = $100-$500/mes

2. **No define l√≠mites de uso:**
   - ¬øCu√°ntos materiales se esperan procesar mensualmente?
   - ¬øHay l√≠mite de materiales por escuela?
   - ¬øQu√© pasa si una escuela sube 10,000 PDFs el primer d√≠a?

3. **No documenta fallback si se excede presupuesto:**
   - ¬øSe pausa procesamiento autom√°tico?
   - ¬øSe cobra extra a la escuela?
   - ¬øSe degrada a modelo m√°s barato (GPT-3.5)?

**Impacto:**
- **BLOQUEANTE MEDIO-ALTO:** No impide desarrollo inicial, pero puede causar sorpresas en producci√≥n
- Riesgo de:
  - Costos no controlados ($1000+/mes inesperados)
  - Necesidad de agregar billing/metering despu√©s (refactor costoso)
  - Degradaci√≥n de servicio sin previo aviso

**Informaci√≥n necesaria:**
1. **Estimaci√≥n de volumen:** ¬øCu√°ntos materiales/mes se esperan?
2. **Costo por material:** Calcular con modelo y longitud promedio
3. **Presupuesto OpenAI:** ¬øCu√°nto del $29,500 es para API?
4. **L√≠mites por tier:** ¬øEscuelas free vs premium?
5. **Estrategia de control de costos:** Rate limiting, quotas, degradaci√≥n

**Soluci√≥n propuesta:**
Agregar a `PRD.md` secci√≥n:
```markdown
### Estimaci√≥n de Costos OpenAI

**Modelo:** GPT-4 Turbo Preview
- Input: $0.01 / 1K tokens
- Output: $0.03 / 1K tokens

**Estimaci√≥n por material:**
- PDF promedio: 20 p√°ginas = 10K tokens input
- Resumen: 1K tokens output
- Quiz: 500 tokens output
- **Costo por material:** ~$0.15

**Volumen esperado:**
- MVP (10 escuelas piloto): 500 materiales/mes
- A√±o 1: 5,000 materiales/mes
- A√±o 2: 20,000 materiales/mes

**Presupuesto OpenAI:**
- MVP: $75/mes ($900/a√±o)
- A√±o 1: $750/mes ($9,000/a√±o)
- A√±o 2: $3,000/mes ($36,000/a√±o)

**L√≠mites por tier:**
- Free tier: 10 materiales/mes con IA
- Basic ($50/mes): 50 materiales/mes
- Premium ($200/mes): 500 materiales/mes
- Enterprise: Ilimitado

**Control de costos:**
- Rate limit: M√°ximo 100 procesamientos/hora
- Si excede quota: Material queda en cola hasta pr√≥ximo mes
- Alertas: Email si gasto mensual > $500
```

---

### 5. Pol√≠tica de Retenci√≥n de Datos Hist√≥ricos

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-01-evaluaciones/02-Design/SECURITY_DESIGN.md:78-95` (menciona GDPR pero no retenci√≥n)
- `AnalisisEstandarizado/spec-01-evaluaciones/02-Design/DATA_MODEL.md:45-78` (tabla immutable pero no dice por cu√°nto tiempo)
- `00-Projects-Isolated/api-mobile/02-Requirements/FUNCTIONAL_SPECS.md:245`

**Descripci√≥n:**
La documentaci√≥n establece:
```
"assessment_attempt es IMMUTABLE (append-only) para auditor√≠a completa"
```

**Por qu√© es ambiguo:**
1. **No especifica duraci√≥n de retenci√≥n:**
   - ¬øSe guardan intentos por siempre?
   - ¬øSe borran despu√©s de X a√±os?
   - ¬øSe archivan a storage fr√≠o?

2. **No aborda GDPR Right to be Forgotten:**
   - GDPR requiere borrar datos de usuario a solicitud
   - Pero tabla es immutable "para auditor√≠a"
   - ¬øC√≥mo se reconcilia?

3. **No define pol√≠tica de anonimizaci√≥n:**
   - Despu√©s de X tiempo, ¬øse anonimizan los intentos?
   - ¬øSe mantiene metadata para analytics pero sin identificar estudiante?

4. **No documenta crecimiento de storage:**
   - Si cada intento = 5KB
   - 1000 estudiantes √ó 100 intentos/a√±o = 500MB/a√±o
   - En 10 a√±os = 5GB solo de intentos
   - ¬øEst√° presupuestado?

**Impacto:**
- **BLOQUEANTE MEDIO:** No impide desarrollo inicial, pero puede causar problemas legales/regulatorios
- Riesgo de:
  - Violaci√≥n de GDPR (multas hasta ‚Ç¨20M)
  - Crecimiento descontrolado de base de datos
  - Costos de storage inesperados

**Informaci√≥n necesaria:**
1. **Duraci√≥n de retenci√≥n:** ¬øCu√°nto tiempo se guardan los datos?
2. **Proceso de borrado:** ¬øC√≥mo se maneja Right to be Forgotten?
3. **Anonimizaci√≥n:** ¬øSe anonimizan datos despu√©s de X tiempo?
4. **Archivado:** ¬øSe mueven a storage fr√≠o despu√©s de X meses?
5. **Compliance:** ¬øQu√© regulaciones aplican (GDPR, FERPA, COPPA)?

**Soluci√≥n propuesta:**
Agregar a `SECURITY_DESIGN.md`:
```markdown
### Pol√≠tica de Retenci√≥n de Datos

**Datos activos (PostgreSQL hot storage):**
- Intentos de evaluaci√≥n: 2 a√±os desde creaci√≥n
- Resultados: 2 a√±os desde creaci√≥n
- Usuarios activos: Mientras cuenta est√© activa

**Archivado (storage fr√≠o):**
- Despu√©s de 2 a√±os: Mover a S3 Glacier
- Formato: JSON comprimido con schema versionado
- Acceso: Solo por request (restore en 24 horas)
- Retenci√≥n en archivo: 5 a√±os adicionales

**Borrado permanente:**
- Despu√©s de 7 a√±os totales: Borrado permanente
- Usuarios inactivos >3 a√±os: Borrado autom√°tico
- Right to be Forgotten: Borrado inmediato a solicitud

**GDPR Right to be Forgotten:**
1. Usuario solicita borrado de cuenta
2. Marcar attempts.student_id como NULL
3. Crear registro anonimizado: `student_id = 'DELETED_USER_{hash}'`
4. Mantener metadata para analytics (sin identificar)
5. Borrar completamente despu√©s de 30 d√≠as

**Anonimizaci√≥n autom√°tica:**
- Despu√©s de 3 a√±os: Anonimizar autom√°ticamente
- Reemplazar student_id con hash irreversible
- Mantener timestamps y scores para analytics
```

---

### 6. Estrategia de Deployment (Blue-Green vs Canary vs Rolling)

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-01-evaluaciones/05-Deployment/DEPLOYMENT_GUIDE.md:89-110`
- `AnalisisEstandarizado/spec-02-worker/05-Deployment/DEPLOYMENT_GUIDE.md:95-115`
- `00-Projects-Isolated/api-mobile/06-Deployment/DEPLOYMENT_GUIDE.md:145-180`

**Descripci√≥n:**
La documentaci√≥n dice:
```
"Deploy a producci√≥n usando CI/CD pipeline con GitHub Actions"
```

No especifica estrategia de deployment.

**Por qu√© es ambiguo:**
1. **No define estrategia de deployment:**
   - ¬øBlue-Green (dos ambientes, switch instant√°neo)?
   - ¬øCanary (despliegue gradual 10% ‚Üí 50% ‚Üí 100%)?
   - ¬øRolling update (actualizar pods uno por uno)?

2. **No documenta manejo de downtime:**
   - ¬øSe espera downtime durante deploy?
   - ¬øHay maintenance window?
   - ¬øO es zero-downtime?

3. **No especifica rollback strategy:**
   - Si nuevo deploy falla, ¬øc√≥mo se revierte?
   - ¬øRollback autom√°tico basado en error rate?
   - ¬øRollback manual?

4. **No aborda compatibilidad de migraciones:**
   - Nueva versi√≥n agrega columna a BD
   - Versi√≥n vieja no la conoce
   - ¬øC√≥mo se maneja durante rolling update?

**Impacto:**
- **BLOQUEANTE MEDIO:** No impide desarrollo, pero puede causar downtime en producci√≥n
- Riesgo de:
  - Deploys que causan downtime no planificado
  - Rollbacks complicados que toman horas
  - Migraciones que rompen versi√≥n vieja durante rolling update

**Informaci√≥n necesaria:**
1. **Estrategia de deployment:** Blue-Green, Canary, o Rolling
2. **SLA de uptime:** ¬ø99.9% requiere zero-downtime?
3. **Estrategia de rollback:** Autom√°tico o manual, trigger conditions
4. **Compatibilidad backward:** ¬øMigraciones deben ser backward compatible?

**Soluci√≥n propuesta:**
Agregar a `DEPLOYMENT_GUIDE.md`:
```markdown
### Estrategia de Deployment

**Ambiente de staging:**
- Blue-Green deployment (switch instant√°neo)
- Testing manual por 1 hora
- Rollback: Switch back to blue environment

**Ambiente de producci√≥n:**
- Canary deployment (gradual rollout)
- Fases:
  1. Deploy a 10% de traffic (10 minutos)
  2. Validar error rate < 1%
  3. Escalar a 50% de traffic (30 minutos)
  4. Validar error rate < 0.5%
  5. Escalar a 100% (full rollout)
- Total tiempo: ~1 hora para full deployment

**Zero-downtime garantizado:**
- No maintenance windows
- Load balancer distribuye traffic entre versiones
- Health checks: Nuevo pod debe pasar checks antes de recibir traffic

**Rollback strategy:**
- Autom√°tico: Si error rate > 5% por 5 minutos ‚Üí rollback
- Manual: Comando `kubectl rollout undo`
- Tiempo de rollback: <5 minutos

**Compatibilidad de migraciones:**
- Migraciones deben ser backward compatible
- Patr√≥n: Agregar columna NULLABLE ‚Üí Deploy c√≥digo ‚Üí Backfill datos ‚Üí Hacer NOT NULL
- Nunca: DROP COLUMN durante rolling update
```

---

### 7. Manejo de Rate Limits de OpenAI

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-02-worker/04-Implementation/Sprint-03-OpenAI-Integration/QUESTIONS.md:28-45`
- `00-Projects-Isolated/worker/04-Implementation/Sprint-03-OpenAI-Integration/TASKS.md:189-210`

**Descripci√≥n:**
La documentaci√≥n dice:
```
"Q003: ¬øQu√© hacer si OpenAI devuelve rate limit (429)?
Decisi√≥n: Retry con backoff exponencial (5 intentos)"
```

**Por qu√© es ambiguo:**
1. **No especifica backoff timing:**
   - ¬øCu√°nto tiempo entre reintentos?
   - ¬ø1 seg, 2 seg, 4 seg, 8 seg, 16 seg?
   - ¬øO m√°s conservador: 30 seg, 60 seg, 120 seg?

2. **No define comportamiento despu√©s de 5 intentos:**
   - ¬øMarcar como fallido y olvidar?
   - ¬øMover a Dead Letter Queue para retry manual?
   - ¬øReintentar en 1 hora autom√°ticamente?

3. **No documenta cola de espera:**
   - Si hay rate limit, probablemente hay muchos materiales en cola
   - ¬øC√≥mo se priorizan?
   - ¬øFIFO, LIFO, por prioridad de escuela?

4. **No especifica notificaci√≥n a usuario:**
   - Docente sube PDF, espera resumen
   - Despu√©s de 5 intentos fallidos, ¬ørecibe notificaci√≥n?
   - ¬øO se queda esperando sin feedback?

**Impacto:**
- **BLOQUEANTE MEDIO:** Worker se implementar√°, pero comportamiento sub-√≥ptimo
- Riesgo de:
  - Reintentos demasiado agresivos que empeoran rate limit
  - Materiales que nunca se procesan sin notificaci√≥n
  - UX pobre (docente no sabe qu√© pas√≥)

**Informaci√≥n necesaria:**
1. **Backoff timing:** Intervalos exactos entre reintentos
2. **Comportamiento despu√©s de max retries:** DLQ, reintento, o fallo permanente
3. **Gesti√≥n de cola:** Priorizaci√≥n y fairness
4. **Notificaciones:** Cu√°ndo y c√≥mo notificar al usuario
5. **Observabilidad:** M√©tricas de rate limiting

**Soluci√≥n propuesta:**
Actualizar `QUESTIONS.md` con decisi√≥n extendida:
```markdown
### Q003: Manejo de Rate Limits OpenAI (Extendido)

**Backoff timing:**
- Intento 1: Inmediato
- Intento 2: 30 segundos despu√©s
- Intento 3: 2 minutos despu√©s
- Intento 4: 5 minutos despu√©s
- Intento 5: 15 minutos despu√©s
- Total m√°ximo: 22.5 minutos

**Despu√©s de 5 intentos fallidos:**
- Mover a Dead Letter Queue (DLQ)
- Reintentar autom√°ticamente en 1 hora
- M√°ximo 3 reintentos desde DLQ
- Si falla 3 veces: Marcar como "permanently_failed"

**Notificaci√≥n a usuario:**
- Despu√©s de primer rate limit: No notificar (retry silencioso)
- Despu√©s de 3 intentos: Email "Procesamiento retrasado, reintentando"
- Despu√©s de marcar como failed: Email "No pudimos procesar tu material, contacta soporte"

**Gesti√≥n de cola:**
- Queue principal: FIFO
- Si rate limit detectado: Pausar consumo por 5 minutos
- Permitir procesamiento de otros tipos de eventos (no OpenAI)

**M√©tricas:**
- Counter: `openai_rate_limit_total`
- Histogram: `openai_retry_duration_seconds`
- Alert: Si >10 rate limits en 1 hora
```

---

### 8. Validaci√≥n de Calidad de Res√∫menes IA

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-02-worker/04-Implementation/Sprint-03-OpenAI-Integration/TASKS.md:245-270`
- `AnalisisEstandarizado/spec-02-worker/05-Testing/TEST_STRATEGY.md:78-95`
- `00-Projects-Isolated/worker/05-Testing/TEST_CASES.md:189-210`

**Descripci√≥n:**
La documentaci√≥n menciona:
```
"Validar que res√∫menes generados cumplan criterios de calidad"
```

No especifica **c√≥mo** validar o **qu√©** criterios.

**Por qu√© es ambiguo:**
1. **No define criterios de calidad medibles:**
   - ¬øLongitud m√≠nima/m√°xima?
   - ¬øPresencia de secciones obligatorias (introducci√≥n, conclusi√≥n)?
   - ¬øLegibilidad (Flesch score)?

2. **No especifica proceso de validaci√≥n:**
   - ¬øValidaci√≥n autom√°tica en c√≥digo?
   - ¬øManual review por QA?
   - ¬øFeedback de usuarios (docentes)?

3. **No documenta qu√© hacer si falla validaci√≥n:**
   - ¬øReintentar generaci√≥n con prompt ajustado?
   - ¬øAceptar resumen y marcar como "needs_review"?
   - ¬øRechazar y notificar error?

4. **No define iteraci√≥n de prompts:**
   - Si res√∫menes son consistentemente malos, ¬øc√≥mo se detecta?
   - ¬øHay A/B testing de prompts?
   - ¬øVersionamiento de prompts?

**Impacto:**
- **BLOQUEANTE MEDIO-BAJO:** Worker funcionar√°, pero calidad inconsistente
- Riesgo de:
  - Res√∫menes in√∫tiles que frustran docentes
  - No hay feedback loop para mejorar
  - NPS bajo (<4/5) sin saber por qu√©

**Informaci√≥n necesaria:**
1. **Criterios de calidad:** M√©tricas objetivas y umbrales
2. **Proceso de validaci√≥n:** Autom√°tico, manual, o h√≠brido
3. **Manejo de fallos:** Retry, aceptar, o rechazar
4. **Mejora continua:** Feedback loop y versionamiento de prompts

**Soluci√≥n propuesta:**
Agregar a `TEST_STRATEGY.md`:
```markdown
### Validaci√≥n de Calidad de Res√∫menes IA

**Criterios autom√°ticos (ejecutados en c√≥digo):**
1. **Longitud:** 500-2000 caracteres
2. **Estructura:** Debe contener al menos 2 secciones (### headers)
3. **Idioma:** Detectar que coincide con idioma del material (es, en, pt)
4. **Completitud:** No contener placeholders como "[TODO]", "[...]"
5. **Formato v√°lido:** Markdown v√°lido sin errores de sintaxis

**Si falla validaci√≥n autom√°tica:**
- Log warning con detalles
- Reintentar generaci√≥n una vez con prompt ajustado
- Si falla segunda vez: Aceptar y marcar `quality_check = 'warning'`

**Criterios manuales (feedback de usuarios):**
1. **Relevancia:** ¬øResumen captura puntos clave? (escala 1-5)
2. **Claridad:** ¬øEs f√°cil de entender? (escala 1-5)
3. **Utilidad:** ¬øAyuda al aprendizaje? (escala 1-5)

**Feedback loop:**
- Cada resumen tiene bot√≥n "üëç √ötil" / "üëé No √∫til"
- Si >20% de thumbs down: Trigger review de prompt
- A/B testing: 10% de usuarios ven prompt variant, comparar NPS

**Versionamiento de prompts:**
- Prompts en Git con versionamiento sem√°ntico (v1.0, v1.1, v2.0)
- Metadata en resumen: `prompt_version = 'v1.2'`
- Analytics: Comparar NPS por versi√≥n de prompt
```

---

### 9. Formato de Archivos Soportados por Worker

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-02-worker/01-Requirements/PRD.md:45-60`
- `AnalisisEstandarizado/spec-02-worker/04-Implementation/Sprint-02-PDF-Processing/TASKS.md:15-30`
- `00-Projects-Isolated/worker/02-Requirements/FUNCTIONAL_SPECS.md:78-95`

**Descripci√≥n:**
La documentaci√≥n dice:
```
"Worker procesa PDFs subidos por docentes para generar res√∫menes y quizzes"
```

**Por qu√© es ambiguo:**
1. **No especifica si solo PDFs o tambi√©n otros formatos:**
   - ¬øDOCX (Word)?
   - ¬øPPTX (PowerPoint)?
   - ¬øTXT (texto plano)?
   - ¬øVideos con transcripci√≥n?
   - ¬øLinks a p√°ginas web?

2. **No define requisitos de PDFs:**
   - ¬øPDFs nativos o escaneados (OCR)?
   - ¬øPDFs protegidos con password?
   - ¬øPDFs con solo im√°genes (sin texto)?
   - ¬øTama√±o m√°ximo (100MB, 1GB)?

3. **No documenta manejo de formatos no soportados:**
   - ¬øRechazar con error?
   - ¬øConvertir autom√°ticamente (DOCX ‚Üí PDF)?
   - ¬øNotificar al docente?

**Impacto:**
- **BLOQUEANTE BAJO:** Worker se implementar√° para PDFs, pero scope incompleto
- Riesgo de:
  - Docentes frustrados que no pueden subir DOCX
  - Necesidad de agregar soporte despu√©s (feature request)
  - UX inconsistente (algunos formatos s√≠, otros no)

**Informaci√≥n necesaria:**
1. **Formatos soportados:** Lista completa (PDF, DOCX, etc.)
2. **Requisitos de PDFs:** Nativo vs OCR, tama√±o m√°ximo, protecci√≥n
3. **Manejo de no soportados:** Error, conversi√≥n, o notificaci√≥n
4. **Roadmap de formatos:** ¬øSe agregar√°n m√°s despu√©s?

**Soluci√≥n propuesta:**
Actualizar `FUNCTIONAL_SPECS.md`:
```markdown
### Formatos de Archivo Soportados

**MVP (Fase 1):**
- ‚úÖ PDF nativo (con texto seleccionable)
- ‚úÖ PDF escaneado (con OCR usando Tesseract)
- ‚ùå DOCX, PPTX, TXT (Post-MVP)
- ‚ùå Videos, Links web (Post-MVP)

**Requisitos de PDFs:**
- Tama√±o m√°ximo: 50MB
- P√°ginas m√°ximas: 500 p√°ginas
- Protecci√≥n: No soportado (rechazar con error)
- Idiomas OCR: Espa√±ol, ingl√©s, portugu√©s

**Manejo de formatos no soportados:**
1. Validar extensi√≥n en upload (api-mobile)
2. Rechazar con error 400: "Formato no soportado. Solo PDF."
3. UI muestra formatos aceptados en upload dialog

**Roadmap de formatos (Post-MVP):**
- Fase 2 (Q2 2026): DOCX, PPTX (convertir a PDF con LibreOffice)
- Fase 3 (Q3 2026): Videos (transcribir con Whisper API)
- Fase 4 (Q4 2026): Links web (scrape con Puppeteer)
```

---

### 10. Compartir Assessments entre Docentes

**Ubicaci√≥n:**
- `AnalisisEstandarizado/spec-01-evaluaciones/01-Requirements/FUNCTIONAL_SPECS.md:89-105`
- `AnalisisEstandarizado/spec-01-evaluaciones/02-Design/API_CONTRACTS.md:145-170`
- `00-Projects-Isolated/api-mobile/02-Requirements/PRD.md:123-140`

**Descripci√≥n:**
La documentaci√≥n especifica:
```
"Teachers pueden crear assessments para sus materiales"
```

No menciona si assessments se pueden compartir entre docentes.

**Por qu√© es ambiguo:**
1. **No define ownership de assessments:**
   - ¬øUn assessment es privado del docente que lo cre√≥?
   - ¬øOtros docentes de la misma escuela pueden usarlo?
   - ¬øHay assessments p√∫blicos (biblioteca compartida)?

2. **No especifica permisos de edici√≥n:**
   - Si Docente A crea assessment, ¬øDocente B puede editarlo?
   - ¬øO solo puede hacer copia y editar su copia?
   - ¬øHay versionamiento (track changes)?

3. **No documenta flujo de compartir:**
   - ¬øDocente A puede "compartir" expl√≠citamente con Docente B?
   - ¬øO todos los assessments de una escuela son p√∫blicos?
   - ¬øHay niveles de visibilidad (privado, escuela, p√∫blico)?

**Impacto:**
- **BLOQUEANTE BAJO:** API funciona para uso individual, pero colaboraci√≥n limitada
- Riesgo de:
  - Duplicaci√≥n de assessments (cada docente recrea el mismo)
  - Feature request inmediata de usuarios ("quiero compartir")
  - Refactor de permisos despu√©s (caro)

**Informaci√≥n necesaria:**
1. **Ownership y visibilidad:** Privado, escuela, o p√∫blico
2. **Permisos de edici√≥n:** Crear, leer, actualizar, borrar (CRUD granular)
3. **Flujo de compartir:** Expl√≠cito o impl√≠cito
4. **Versionamiento:** Track changes o solo √∫ltima versi√≥n

**Soluci√≥n propuesta:**
Agregar a `FUNCTIONAL_SPECS.md`:
```markdown
### Compartir Assessments entre Docentes

**MVP (Fase 1):**
- Assessments son privados del docente creador
- No se pueden compartir entre docentes
- Cada docente crea sus propios assessments

**Post-MVP (Fase 2 - Q2 2026):**
- Agregar niveles de visibilidad:
  - `private`: Solo creador
  - `school`: Todos los docentes de la escuela pueden ver y copiar
  - `public`: Biblioteca p√∫blica de assessments (futuro marketplace)
- Flujo de compartir:
  - Docente A marca assessment como `school` visibility
  - Docente B ve en "Biblioteca de Assessments" de su escuela
  - Docente B puede "Usar" (readonly) o "Copiar y Editar" (fork)
- Permisos:
  - Creador: Full CRUD
  - Otros docentes: Read + Copy (no editar original)
- Versionamiento:
  - No en MVP (solo √∫ltima versi√≥n)
  - Post-MVP: Track versions con `assessment_version` table

**Schema cambios (Fase 2):**
```sql
ALTER TABLE assessment ADD COLUMN visibility VARCHAR(20) DEFAULT 'private';
ALTER TABLE assessment ADD COLUMN created_by_teacher_id UUID;
CREATE INDEX idx_assessment_visibility ON assessment(visibility, school_id);
```
```

---

## üü° Ambig√ºedades Menores (No Bloqueantes)

### 11. Idiomas Soportados para Res√∫menes IA

**Ubicaci√≥n:** `spec-02-worker/02-Design/ARCHITECTURE.md`

**Ambig√ºedad:** No especifica qu√© idiomas soporta OpenAI para res√∫menes.

**Impacto:** Bajo - Se puede asumir espa√±ol, ingl√©s, portugu√©s (LATAM).

**Soluci√≥n:** Documentar idiomas soportados y validaci√≥n de idioma del material.

---

### 12. Tama√±o M√°ximo de PDF a Procesar

**Ubicaci√≥n:** `spec-02-worker/01-Requirements/TECHNICAL_SPECS.md`

**Ambig√ºedad:** No especifica l√≠mite de tama√±o o n√∫mero de p√°ginas.

**Impacto:** Bajo - Puede causar timeouts con PDFs muy grandes.

**Soluci√≥n:** Establecer l√≠mite (ej: 50MB, 500 p√°ginas) y documentar.

---

### 13. Profundidad M√°xima de Jerarqu√≠a Acad√©mica

**Ubicaci√≥n:** `spec-03-api-administracion/02-Design/ARCHITECTURE.md:145`

**Documentado como:** "5 niveles m√°ximo"

**Ambig√ºedad:** No especifica qu√© hacer si se intenta crear nivel 6.

**Impacto:** Bajo - Validaci√≥n faltante.

**Soluci√≥n:** Agregar validaci√≥n que rechace parent_id si profundidad > 5.

---

### 14. Tiempo de Expiraci√≥n de Tokens JWT

**Ubicaci√≥n:** `00-Overview/ECOSYSTEM_OVERVIEW.md:78`

**Documentado como:** "15 minutos access token, 7 d√≠as refresh token"

**Ambig√ºedad:** No especifica si tiempos son configurables o hardcoded.

**Impacto:** Bajo - Puede necesitar ajuste despu√©s.

**Soluci√≥n:** Hacer configurable v√≠a variable de entorno `JWT_ACCESS_EXPIRY=15m`.

---

### 15. Puerto de Mongo Express en Dev Environment

**Ubicaci√≥n:** `00-Projects-Isolated/dev-environment/03-Design/NETWORKING_DESIGN.md`

**Ambig√ºedad:** Mongo Express t√≠picamente usa 8081, conflicto con api-admin.

**Impacto:** Bajo - Docker Compose fallar√° si no se ajusta.

**Soluci√≥n:** Mapear Mongo Express a puerto 8082 en `docker-compose.yml`.

---

### 16. Estrategia de Logging en Producci√≥n

**Ubicaci√≥n:** `spec-04-shared/04-Implementation/Sprint-01-Core/TASKS.md:45`

**Documentado como:** "Implementar logger con Logrus"

**Ambig√ºedad:** No especifica d√≥nde se almacenan logs en producci√≥n.

**Impacto:** Bajo - Se puede usar stdout y capturar con Kubernetes.

**Soluci√≥n:** Documentar que logs van a stdout, capturados por Fluentd/Loki.

---

### 17. Healthcheck Endpoints

**Ubicaci√≥n:** `spec-01/05-Deployment/MONITORING.md:89`

**Documentado como:** "Implementar /health endpoint"

**Ambig√ºedad:** No especifica qu√© checks incluye (DB, RabbitMQ, etc.).

**Impacto:** Bajo - Healthcheck b√°sico funciona, pero no detecta dependencias.

**Soluci√≥n:** Documentar healthcheck completo:
```go
/health/liveness  // b√°sico (API responde)
/health/readiness // completo (DB + RabbitMQ + MongoDB)
```

---

### 18. Convenci√≥n de Nombres de Branches

**Ubicaci√≥n:** `spec-06-CI-CD/06-Deployment/DEPLOYMENT_GUIDE.md`

**Ambig√ºedad:** No especifica convenci√≥n de branches (main, develop, feature/*).

**Impacto:** Bajo - Puede causar confusi√≥n en PRs.

**Soluci√≥n:** Documentar Git Flow:
```
main - producci√≥n
develop - desarrollo
feature/* - features
fix/* - bugs
```

---

## üìä Resumen de Ambig√ºedades

### Por Severidad

| Severidad | Cantidad | % del Total |
|-----------|----------|-------------|
| üî¥ Cr√≠ticas (Bloqueantes) | 10 | 56% |
| üü° Menores (No Bloqueantes) | 8 | 44% |
| **TOTAL** | **18** | **100%** |

### Por Categor√≠a

| Categor√≠a | Cr√≠ticas | Menores | Total |
|-----------|----------|---------|-------|
| Arquitectura de Datos | 3 | 0 | 3 |
| Servicios Externos (OpenAI) | 2 | 2 | 4 |
| Deployment & Ops | 2 | 3 | 5 |
| Compliance & Seguridad | 1 | 0 | 1 |
| Features & UX | 2 | 3 | 5 |
| **TOTAL** | **10** | **8** | **18** |

### Top 3 Ambig√ºedades M√°s Cr√≠ticas

1. **Sincronizaci√≥n PostgreSQL ‚Üî MongoDB** - Riesgo de inconsistencias de datos
2. **Ownership de Tablas Compartidas** - Riesgo de fallos de migraciones
3. **SLA de OpenAI** - Riesgo de costos descontrolados y UX pobre

---

## ‚úÖ Pr√≥ximos Pasos Recomendados

1. **Resolver ambig√ºedades cr√≠ticas (1-3)** antes de iniciar desarrollo de api-mobile
2. **Resolver ambig√ºedades cr√≠ticas (4-6)** antes de iniciar worker
3. **Resolver ambig√ºedades cr√≠ticas (7-10)** durante implementaci√≥n (menos urgentes)
4. **Ambig√ºedades menores (11-18)** se pueden resolver con defaults razonables

**Tiempo estimado para resolver cr√≠ticas:** 8-12 horas de documentaci√≥n

---

**Fin del An√°lisis de Ambig√ºedades**
