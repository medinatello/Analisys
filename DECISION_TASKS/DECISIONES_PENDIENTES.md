# ğŸ¯ Decisiones Pendientes - EduGo

**Fecha:** 15 de Noviembre, 2025
**Estado:** âœ… edugo-shared v0.7.0 resuelto | â¬œ 4 decisiones crÃ­ticas pendientes
**Objetivo:** Tomar decisiones para desbloquear desarrollo

---

## ğŸ“– CÃ³mo Usar Este Documento

1. **Lee cada secciÃ³n** (son 4 decisiones crÃ­ticas)
2. **Entiende el problema** y sus implicaciones
3. **Revisa las soluciones propuestas** con pros/contras
4. **Escribe tu decisiÃ³n** en el espacio "TU DECISIÃ“N"
5. **Guarda el documento** y avÃ­same cuando termines
6. **Yo generarÃ© las tareas** basado en tus decisiones

**Tiempo estimado:** 30-45 minutos para leer y decidir todo

---

# SESIÃ“N 1: Ownership de Tablas Compartidas

## ğŸ”´ PROBLEMA

**Â¿QuÃ© pasa?**
- La tabla `users` es mencionada tanto en **api-admin** como en **api-mobile**
- La tabla `materials` es mencionada en **api-mobile** pero no queda claro si la crea o asume que existe
- Las tablas `schools`, `academic_units` tambiÃ©n son ambiguas

**Â¿Por quÃ© es un problema?**
- Si ambos proyectos intentan crear la misma tabla â†’ Error "table already exists"
- Si ninguno la crea â†’ Error "table does not exist"
- Las migraciones no tienen orden garantizado en CI/CD

**Â¿DÃ³nde se genera?**
- En las migraciones de base de datos de cada proyecto:
  - `api-admin/migrations/001_create_users.sql`
  - `api-mobile/migrations/00X_create_materials.sql`

**Â¿QuÃ© inconveniente trae?**
- âŒ Migraciones fallan de manera impredecible
- âŒ CI/CD no puede ejecutar migraciones automÃ¡ticamente
- âŒ Desarrollo local inconsistente (cada dev con esquema diferente)
- âŒ Tests de integraciÃ³n rompen aleatoriamente
- âŒ Imposible hacer development desatendido por IA

---

## ğŸ’¡ SOLUCIONES PROPUESTAS

### OpciÃ³n 1: api-admin crea TODAS las tablas base, api-mobile solo features

**CÃ³mo funciona:**
```
api-admin crea:
â”œâ”€ users (todas las columnas necesarias)
â”œâ”€ schools
â”œâ”€ academic_units
â”œâ”€ memberships
â””â”€ [otras tablas de administraciÃ³n]

api-mobile crea:
â”œâ”€ materials (con FK a users, schools)
â”œâ”€ assessment (con FK a materials)
â”œâ”€ assessment_attempt
â””â”€ [tablas especÃ­ficas de mobile]

Orden de ejecuciÃ³n:
1. api-admin ejecuta migraciones PRIMERO
2. api-mobile ejecuta migraciones DESPUÃ‰S
```

**âœ… Pros:**
- SeparaciÃ³n clara de responsabilidades
- api-admin es "fundaciÃ³n", api-mobile es "features"
- FÃ¡cil de entender y documentar
- CI/CD tiene orden claro: admin â†’ mobile

**âŒ Contras:**
- Si api-mobile necesita agregar columna a `users`, debe coordinar con api-admin
- api-admin se vuelve "cuello de botella" para cambios de esquema

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear tabla en: docs/DATABASE_OWNERSHIP.md
2. Modificar Makefile de api-mobile para validar tablas base
3. CI/CD ejecuta: api-admin migrate â†’ api-mobile migrate
4. Tiempo: 3-4 horas
```

**ğŸ¯ Impacto:**
- âœ… Cero conflictos de migraciones
- âœ… Orden claro y documentado
- âš ï¸ Acoplamiento entre proyectos en cambios de esquema

---

### OpciÃ³n 2: Cada proyecto crea SOLO sus tablas, usar migraciones condicionales

**CÃ³mo funciona:**
```sql
-- api-admin/migrations/001_create_users.sql
CREATE TABLE IF NOT EXISTS users (...);

-- api-mobile/migrations/001_create_users_if_needed.sql
CREATE TABLE IF NOT EXISTS users (...);
CREATE TABLE materials (...);
```

**âœ… Pros:**
- Cada proyecto es "autocontenido"
- No importa el orden de ejecuciÃ³n
- MÃ¡s flexible para desarrollo independiente

**âŒ Contras:**
- Riesgo de esquemas inconsistentes (Â¿quÃ© columnas tiene `users`?)
- DifÃ­cil de mantener (cambios deben replicarse en mÃºltiples lugares)
- Debugging complejo cuando algo falla
- No es una prÃ¡ctica estÃ¡ndar en la industria

**âš™ï¸ ImplementaciÃ³n:**
```
1. Duplicar definiciones de tablas compartidas
2. Usar CREATE TABLE IF NOT EXISTS
3. Validar esquemas con tests
4. Tiempo: 5-6 horas + mantenimiento continuo
```

**ğŸ¯ Impacto:**
- âœ… Proyectos independientes
- âŒ Riesgo alto de inconsistencias
- âŒ Mantenimiento complicado

---

### OpciÃ³n 3: Crear proyecto separado "database-schema" que ejecuta primero

**CÃ³mo funciona:**
```
Nuevo proyecto: edugo-database-schema/
â”œâ”€ migrations/
â”‚   â”œâ”€ 001_create_users.sql
â”‚   â”œâ”€ 002_create_schools.sql
â”‚   â””â”€ 003_create_materials.sql  (Â¿o solo tablas compartidas?)

Orden en CI/CD:
1. edugo-database-schema migrate
2. api-admin migrate (solo cambios especÃ­ficos)
3. api-mobile migrate (solo cambios especÃ­ficos)
```

**âœ… Pros:**
- SeparaciÃ³n total de concerns
- Esquema centralizado y versionado
- FÃ¡cil de auditar cambios de BD

**âŒ Contras:**
- Nuevo proyecto = mÃ¡s complejidad
- Overhead de mantenimiento de otro repo
- Requiere coordinaciÃ³n para cambios

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear nuevo repo edugo-database-schema
2. Mover migraciones compartidas
3. Actualizar CI/CD (3 pasos en lugar de 2)
4. Tiempo: 6-8 horas
```

**ğŸ¯ Impacto:**
- âœ… MÃ¡xima claridad de ownership
- âŒ Complejidad adicional de gestiÃ³n
- âš ï¸ Overkill para proyecto actual

---

## ğŸ“ TU DECISIÃ“N

**OpciÃ³n elegida:** ____Otra_____ (Escribe: OpciÃ³n 1, OpciÃ³n 2, OpciÃ³n 3, u "Otra")

**Si eliges "Otra", describe tu soluciÃ³n:**
```
Esto no son microservicios, ya que las bases de datos son compartidas y los servidores como rabbit
El enfoque de tener 2 apis, se enfoca mas por mas consumo de llamadas, donde api-mobile, seran los endpoint mas usado, y api-admin, son endpoint menos consumido, desde ese punto de vista, ninguna de las dos tienen responsabilidad clara del ambiente, en teoria la responsabilidad debe ser /Users/jhoanmedina/source/EduGo/repos-separados/edugo-dev-environment, ya que alli hay dockerfile y compose para crear el ambiente trasversal, pero dar esa responsabilidad, no es viable, porque en el momento de hacer los test de integracion, necesito tener las tablas creadas con datos de prueba, y mismo tema cuando quiera correr solo una api, crear el ambiente local minimo

Siento que aca puede venir un nuevo proyecto o rehusar el proyecto shared para que tenga un modulo de migracion, y scripts varios, alli estaria la responsabilidad de crear las tablas, y los scripts para crear el ambiente local minimo, y los scripts para correr los test de integracion, y asi cada api solo se enfoca en su logica de negocio, apostar por un nuevo proyecto me suena mas logico, ya que rehusar shared, lo saca de su estado congelado, ademas se esta recargando de responsabilidades

Entonces prefiero crear un nuevo proyecto, de base de datos, y que alli esten las migraciones de todas las tablas, y los scripts para crear el ambiente local minimo, y los scripts para correr los test de integracion (no logica de tests, sino scripts necesarios para la migracion), es capaz que hasta a nive de diseÃ±o arquitectonico, podemamos importar shared para usar el area de base de datos, y asi no duplicar codigo, y tener un proyecto dedicado a la base de datos, y scripts necesarios para crear el ambiente local minimo, y correr los test de integracion, y shared funciones mas generica

```

**RazÃ³n de tu decisiÃ³n:**
```
[Â¿Por quÃ© elegiste esta opciÃ³n? Â¿QuÃ© te convenciÃ³?]
En el punto anterior explico bien mi razonamiento
```

**Tablas que quieres que api-admin cree (si aplica):**
```
[ ] users
[ ] schools
[ ] academic_units
[ ] memberships
[ ] Otra: ___N/A_______
```

**Tablas que quieres que api-mobile cree (si aplica):**
```
[ ] materials
[ ] assessment
[ ] assessment_attempt
[ ] assessment_attempt_answer
[ ] Otra: _____N/A_____
```

---

# SESIÃ“N 2: Contratos de Eventos RabbitMQ

## ğŸ”´ PROBLEMA

**Â¿QuÃ© pasa?**
- **api-mobile** publica evento `material.uploaded` cuando un docente sube un PDF
- **worker** consume ese evento para generar resumen con OpenAI
- Pero NO estÃ¡ especificado el formato JSON exacto del evento

**Â¿Por quÃ© es un problema?**
- api-mobile puede enviar: `{"material_id": "123", "file_path": "/uploads/file.pdf"}`
- worker puede esperar: `{"materialId": "123", "s3_url": "s3://..."}`
- â†‘ Incompatibilidad = evento se pierde en el vacÃ­o, worker no procesa nada

**Â¿DÃ³nde se genera?**
- `api-mobile/internal/messaging/publisher.go` â†’ Publica evento
- `worker/internal/messaging/consumer.go` â†’ Consume evento
- Sin especificaciÃ³n compartida

**Â¿QuÃ© inconveniente trae?**
- âŒ worker no procesa materiales (feature principal bloqueada)
- âŒ Breaking changes sin aviso (api-mobile actualiza formato, worker rompe)
- âŒ Debugging imposible (Â¿quÃ© campo falta? Â¿cuÃ¡l sobra?)
- âŒ Desarrollo independiente bloqueado (necesitas coordinar manualmente)

---

## ğŸ’¡ SOLUCIONES PROPUESTAS

### OpciÃ³n 1: Documento de contratos JSON (enfoque lightweight)

**CÃ³mo funciona:**
```markdown
# docs/EVENT_CONTRACTS.md

## material.uploaded (v1.0)

Publicado por: api-mobile
Consumido por: worker
Exchange: edugo.topic
Routing key: material.uploaded

{
  "event_id": "uuid-v7",              // ID Ãºnico del evento
  "event_type": "material.uploaded",
  "event_version": "1.0",             // Importante para breaking changes
  "timestamp": "2025-11-15T10:30:00Z",
  "payload": {
    "material_id": "uuid",            // ID en PostgreSQL
    "school_id": "uuid",
    "teacher_id": "uuid",
    "file_url": "s3://bucket/key",
    "file_size_bytes": 2048000,
    "file_type": "application/pdf",
    "metadata": {
      "title": "FÃ­sica CuÃ¡ntica",
      "grade": "10th"
    }
  }
}
```

**âœ… Pros:**
- Simple y rÃ¡pido de implementar (1 hora)
- FÃ¡cil de leer y entender
- No requiere librerÃ­as adicionales
- Flexible para cambios rÃ¡pidos

**âŒ Contras:**
- No se valida automÃ¡ticamente (confianza en devs)
- Requiere disciplina para mantenerlo actualizado
- Sin validaciÃ³n en tiempo de ejecuciÃ³n

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear docs/EVENT_CONTRACTS.md
2. Documentar 2-3 eventos principales
3. Referenciarlo en README de api-mobile y worker
4. Tiempo: 1-2 horas
```

**ğŸ¯ Impacto:**
- âœ… Claridad inmediata
- âœ… FÃ¡cil de iterar
- âš ï¸ Requiere disciplina manual

---

### OpciÃ³n 2: JSON Schema con validaciÃ³n automÃ¡tica

**CÃ³mo funciona:**
```json
// shared/schemas/material-uploaded-v1.schema.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["event_id", "event_type", "payload"],
  "properties": {
    "event_id": {"type": "string", "format": "uuid"},
    "event_type": {"const": "material.uploaded"},
    "event_version": {"const": "1.0"},
    "payload": {
      "type": "object",
      "required": ["material_id", "file_url"],
      "properties": {
        "material_id": {"type": "string", "format": "uuid"},
        "file_url": {"type": "string", "format": "uri"}
      }
    }
  }
}
```

**Uso en cÃ³digo:**
```go
// api-mobile: Validar antes de publicar
if err := validator.Validate(event, schema); err != nil {
    return fmt.Errorf("invalid event: %w", err)
}
publisher.Publish(event)

// worker: Validar al consumir
if err := validator.Validate(event, schema); err != nil {
    logger.Error("invalid event received", err)
    return // o enviar a DLQ
}
```

**âœ… Pros:**
- ValidaciÃ³n automÃ¡tica en runtime
- Errores detectados inmediatamente
- DocumentaciÃ³n ejecutable (schema = contrato)
- Breaking changes detectados antes de producciÃ³n

**âŒ Contras:**
- MÃ¡s complejo de implementar (librerÃ­a de validaciÃ³n)
- Overhead de performance (validaciÃ³n en cada evento)
- Curva de aprendizaje de JSON Schema

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear schemas/ en shared/
2. Agregar librerÃ­a de validaciÃ³n (xeipuuv/gojsonschema)
3. Implementar validaciÃ³n en publisher/consumer
4. Tiempo: 4-5 horas
```

**ğŸ¯ Impacto:**
- âœ… MÃ¡xima seguridad
- âœ… Errores detectados temprano
- âš ï¸ Mayor complejidad tÃ©cnica

---

### OpciÃ³n 3: Protobuf (enfoque enterprise)

**CÃ³mo funciona:**
```protobuf
// shared/protos/events.proto
syntax = "proto3";

message MaterialUploaded {
  string event_id = 1;
  string event_type = 2;
  string event_version = 3;
  google.protobuf.Timestamp timestamp = 4;

  message Payload {
    string material_id = 1;
    string school_id = 2;
    string teacher_id = 3;
    string file_url = 4;
    int64 file_size_bytes = 5;
  }

  Payload payload = 5;
}
```

**âœ… Pros:**
- Tipado fuerte (compilador detecta errores)
- MÃ¡s eficiente en tamaÃ±o (binary vs JSON)
- Versionamiento built-in
- Usado en producciÃ³n por Google, Uber, Netflix

**âŒ Contras:**
- Complejidad alta (protoc, generaciÃ³n de cÃ³digo)
- Curva de aprendizaje
- Overkill para proyecto actual
- Requiere cambio de paradigma (no es JSON)

**âš™ï¸ ImplementaciÃ³n:**
```
1. Setup protoc compiler
2. Definir .proto files
3. Generar cÃ³digo Go
4. Actualizar publisher/consumer
5. Tiempo: 8-10 horas + aprendizaje
```

**ğŸ¯ Impacto:**
- âœ… MÃ¡xima robustez
- âŒ Complejidad excesiva para MVP
- âš ï¸ Recomendado solo post-MVP

---

## ğŸ“ TU DECISIÃ“N

**OpciÃ³n elegida:** ____2_____ (Escribe: OpciÃ³n 1, OpciÃ³n 2, OpciÃ³n 3, u "Otra")

**Si eliges "Otra", describe tu soluciÃ³n:**
```
[Tu soluciÃ³n aquÃ­]
```

**RazÃ³n de tu decisiÃ³n:**
```
[Â¿Por quÃ© elegiste esta opciÃ³n?]
Quiero que aunque sea un poco mas complejo al inicio, es mas estaticos y estandarizado
```

**Eventos que necesitas documentar (marca los que aplican):**
```
[X] material.uploaded (api-mobile â†’ worker)
[X] assessment.generated (worker â†’ api-mobile)
[X] material.deleted (api-mobile â†’ worker)
[X] student.enrolled (api-admin â†’ api-mobile)
[ ] Otro: __________
```

**Estrategia de versionamiento que prefieres:**
```
[X] event_version en JSON (ej: "1.0", "1.1", "2.0")
[ ] Routing keys separados (ej: material.uploaded.v1, material.uploaded.v2)
[ ] Sin versionamiento por ahora (agregar despuÃ©s si es necesario)
[ ] Otra: __________
```

---

# SESIÃ“N 3: docker-compose.yml para Desarrollo Local

## ğŸ”´ PROBLEMA

**Â¿QuÃ© pasa?**
- El archivo `dev-environment/docker-compose.yml` **NO EXISTE**
- Los scripts `setup.sh`, `seed-data.sh` **NO EXISTEN**
- Seeds de datos de prueba **NO EXISTEN**

**Â¿Por quÃ© es un problema?**
- Un desarrollador nuevo clona el repo y... Â¿cÃ³mo levanta PostgreSQL? Â¿MongoDB? Â¿RabbitMQ?
- Cada dev configura a su manera â†’ inconsistencias
- Tests de integraciÃ³n no se pueden ejecutar sin infraestructura

**Â¿DÃ³nde se genera?**
- Proyecto `dev-environment` existe pero estÃ¡ vacÃ­o (solo documentaciÃ³n)

**Â¿QuÃ© inconveniente trae?**
- âŒ Onboarding de nuevos devs es manual y lento (1-2 horas)
- âŒ Tests de integraciÃ³n no se pueden ejecutar en local
- âŒ CI/CD no puede ejecutar tests de integraciÃ³n
- âŒ Desarrollo desatendido por IA bloqueado (no puede levantar infra)
- âŒ Cada dev con versiones diferentes de PostgreSQL/MongoDB

---

## ğŸ’¡ SOLUCIONES PROPUESTAS

### OpciÃ³n 1: docker-compose.yml completo con todos los servicios

**CÃ³mo funciona:**
```yaml
# dev-environment/docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    ports: ["5432:5432"]
    environment:
      POSTGRES_DB: edugo_dev
      POSTGRES_USER: edugo
      POSTGRES_PASSWORD: changeme
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongodb:
    image: mongo:7.0
    ports: ["27017:27017"]
    volumes:
      - mongo_data:/data/db

  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    ports:
      - "5672:5672"    # AMQP
      - "15672:15672"  # Management UI

  # Herramientas opcionales
  mongo-express:
    image: mongo-express
    ports: ["8082:8081"]
    profiles: ["tools"]

  pgadmin:
    image: dpage/pgadmin4
    ports: ["5050:80"]
    profiles: ["tools"]

volumes:
  postgres_data:
  mongo_data:
```

**Scripts incluidos:**
```bash
# scripts/setup.sh
#!/bin/bash
docker-compose up -d
sleep 5
./scripts/seed-data.sh

# scripts/seed-data.sh
#!/bin/bash
psql -h localhost -U edugo -d edugo_dev < seeds/postgres/users.sql
mongosh localhost:27017/edugo < seeds/mongodb/materials.js
```

**âœ… Pros:**
- Setup en 1 comando: `./scripts/setup.sh`
- Todos los devs con misma configuraciÃ³n
- CI/CD puede usar los mismos servicios
- Herramientas de debugging opcionales (PgAdmin, Mongo Express)

**âŒ Contras:**
- Requiere Docker instalado (dependency)
- Seeds de datos hay que crearlos manualmente

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear docker-compose.yml
2. Crear scripts/setup.sh
3. Crear scripts/seed-data.sh
4. Crear seeds bÃ¡sicos (5-10 registros por tabla)
5. Crear .env.example
6. Tiempo: 4-5 horas
```

**ğŸ¯ Impacto:**
- âœ… Onboarding de 2 horas â†’ 5 minutos
- âœ… Tests de integraciÃ³n habilitados
- âœ… Desarrollo consistente entre devs

---

### OpciÃ³n 2: docker-compose.yml mÃ­nimo + instrucciones manuales

**CÃ³mo funciona:**
```yaml
# Solo servicios bÃ¡sicos, sin herramientas
services:
  postgres:
    image: postgres:15-alpine
    ports: ["5432:5432"]

  mongodb:
    image: mongo:7.0
    ports: ["27017:27017"]

  rabbitmq:
    image: rabbitmq:3.12-alpine
    ports: ["5672:5672"]
```

**Sin scripts automatizados:**
```markdown
# README.md
## Setup Manual

1. docker-compose up -d
2. Ejecutar migraciones: cd api-admin && make migrate
3. Cargar datos: psql < seeds/users.sql (crear manualmente)
```

**âœ… Pros:**
- MÃ¡s simple (menos cÃ³digo)
- Flexibilidad para cada dev

**âŒ Contras:**
- Setup sigue siendo manual (10-15 min)
- Propenso a errores (Â¿quÃ© si olvido un paso?)
- Sin seeds = cada dev crea sus datos

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear docker-compose.yml mÃ­nimo
2. Documentar pasos en README
3. Tiempo: 1-2 horas
```

**ğŸ¯ Impacto:**
- âœ… BÃ¡sico funcionando
- âš ï¸ Requiere seguir pasos manuales
- âŒ No ideal para IA desatendida

---

### OpciÃ³n 3: Makefile con comandos unificados

**CÃ³mo funciona:**
```makefile
# dev-environment/Makefile

.PHONY: setup
setup: ## Levantar todo y sembrar datos
	@docker-compose up -d
	@echo "Esperando que servicios estÃ©n listos..."
	@sleep 10
	@$(MAKE) seed

.PHONY: seed
seed: ## Sembrar datos de prueba
	@echo "Sembrando PostgreSQL..."
	@psql -h localhost -U edugo -f seeds/postgres/all.sql
	@echo "Sembrando MongoDB..."
	@mongosh localhost:27017/edugo < seeds/mongodb/all.js

.PHONY: teardown
teardown: ## Limpiar todo
	@docker-compose down -v

.PHONY: reset
reset: teardown setup ## Reset completo (teardown + setup)
```

**Uso:**
```bash
make setup      # Primera vez o despuÃ©s de cambios
make reset      # Limpiar y empezar de cero
make teardown   # Limpiar al terminar
```

**âœ… Pros:**
- Comandos simples y memorizables
- Makefile es estÃ¡ndar en proyectos Go
- FÃ¡cil agregar comandos nuevos

**âŒ Contras:**
- Requiere make instalado (pero Go devs lo tienen)
- Un poco mÃ¡s de cÃ³digo que scripts bash

**âš™ï¸ ImplementaciÃ³n:**
```
1. Crear Makefile con targets
2. Crear docker-compose.yml
3. Crear seeds/
4. Documentar en README: "make setup"
5. Tiempo: 4-5 horas
```

**ğŸ¯ Impacto:**
- âœ… Setup en 1 comando memorable
- âœ… FÃ¡cil de extender
- âœ… ConvenciÃ³n estÃ¡ndar

---

## ğŸ“ TU DECISIÃ“N

**OpciÃ³n elegida:** ____Otra_____ (Escribe: OpciÃ³n 1, OpciÃ³n 2, OpciÃ³n 3, u "Otra")

**Si eliges "Otra", describe tu soluciÃ³n:***
```
Bueno esto esta muy relacionado con el punto 1, ya en ese punto se mando hacer un proyecto para manejar el tema de la migracion, entonces en este punto, ese proyecto nuevo, puede tener el docker-compose.yml, los scripts de setup y seed, y los seeds de datos, asi todo lo relacionado con la base de datos y el ambiente local minimo, queda en un solo proyecto, y cada api solo se enfoca en su logica de negocio, ademas de que ese proyecto nuevo, puede rehusar shared para no duplicar codigo, y asi shared sigue congelado en su estado actual, a lo cual el nombre de proyecto deberia cambiar, ya que si es cierto que su funcion principal era migracion de base de datos, pero aca se va agregar otros contenedores, por eso, dime como deberiamos cambiarlo.
Este proyecto unificado debe tener la responsabilidad de
* Scritps de estructura de las bases de datos y contraints varios
* Scritps con datos de inicios si los hay
* Scritps con datos de prueba (seeds)
* Aunque no lo veo a nivel de implementacion, te coloco lo que se debe tener, y luego le damos la vuelta de como lo va a invocar cada proyecto
    * Docker file y Docker compose:
      * N Docker File por cada proyecto
      * Docker compose unificado
      * Docker compose de cada proyecto, es decir, si api admin no necesita rabbit no deberia levantarlo
      * El punto anterior es que no se como diagramarlo pero la idea que si quiero prgramar en api-admin, y no tengo el ambiente ejecutar lo que necesito como minimo, sabemos que la base de datos es todo.
      * No se si los testcontainer en go necesita docker compose para ellos, entonces pensar que no todos los proyectos prueba lo mismo
      * El proyecto /Users/jhoanmedina/source/EduGo/repos-separados/edugo-dev-environment deberia de tener acceso al docker compose unificado, (como dije no se como hacerlo pero la idea es que se modifique en un solo lugar)
```

**RazÃ³n de tu decisiÃ³n:**
```
[Â¿Por quÃ© elegiste esta opciÃ³n?]
```

**Servicios que necesitas en docker-compose:**
```
[X] PostgreSQL 15
[X] MongoDB 7.0
[X] RabbitMQ 3.12
[X] Mongo Express (herramienta visual para MongoDB)
[X] PgAdmin (herramienta visual para PostgreSQL)
[X] Redis (si lo necesitas para cachÃ©)
[ ] Otro: __________
```

**Seeds de datos que necesitas:**
```
[X] 2-3 usuarios de prueba (admin, teacher, student)
[X] 1-2 escuelas de prueba
[X] 3-5 materiales de prueba
[X] 1-2 assessments de prueba
[ ] Otro: __________
```

**Herramienta de ejecuciÃ³n preferida:**
```
[ ] Scripts bash (setup.sh, seed-data.sh)
[X] Makefile (make setup, make seed)
[X] Docker compose commands directos (docker-compose up)
[ ] Otra: __________
Creo que Makefile puede ayudar para cuando se quiera solo instalar lo que necesita la api, o si debe actualizar algo referente a este punto
Docker compose, cuando quieras levantar todo el ambiente, es decir cada proyecto tendra las 2 opciones pero el compose es para todo, makefile es para lo necesario del proyecto, y la solucion para los testcontainer alli si hay que saber como se puede centralizar
```

---

# SESIÃ“N 4: SincronizaciÃ³n PostgreSQL â†” MongoDB

## ğŸ”´ PROBLEMA

**Â¿QuÃ© pasa?**
- La tabla `assessment` en **PostgreSQL** tiene columna `mongo_document_id VARCHAR(24)`
- Los quizzes/preguntas estÃ¡n en **MongoDB** colecciÃ³n `material_assessment`
- Pero NO estÃ¡ claro:
  - Â¿Se crea primero el documento en MongoDB o el registro en PostgreSQL?
  - Â¿QuÃ© pasa si MongoDB falla despuÃ©s de crear en PostgreSQL?
  - Â¿QuÃ© pasa si PostgreSQL falla despuÃ©s de crear en MongoDB?

**Â¿Por quÃ© es un problema?**
- Sin patrÃ³n definido â†’ cada dev implementa diferente
- Riesgo de **orphan records**: registro en PostgreSQL sin documento en MongoDB (o viceversa)
- Riesgo de **race conditions**: dos sistemas se actualizan en orden impredecible

**Â¿DÃ³nde se genera?**
- `worker/internal/services/assessment_service.go` â†’ Genera assessment en MongoDB
- `api-mobile/internal/services/assessment_service.go` â†’ Lee/actualiza assessment

**Â¿QuÃ© inconveniente trae?**
- âŒ Datos inconsistentes (assessment exists en PG pero no en Mongo)
- âŒ 500 errors al intentar leer (app busca en Mongo pero no existe)
- âŒ Debugging complejo (Â¿dÃ³nde estÃ¡ el problema?)
- âŒ Rollbacks imposibles (Â¿cÃ³mo deshacer cambio en 2 BDs?)

---

## ğŸ’¡ SOLUCIONES PROPUESTAS

### OpciÃ³n 1: MongoDB primero + Evento (Eventual Consistency)

**CÃ³mo funciona:**
```
Flujo de creaciÃ³n:
1. Worker genera assessment en MongoDB
   â”œâ”€ ColecciÃ³n: material_assessment
   â”œâ”€ _id: ObjectId("507f1f77bcf86cd799439011")
   â””â”€ Contiene: {questions: [...], metadata: {...}}

2. Worker publica evento: assessment.generated
   â”œâ”€ Exchange: edugo.topic
   â”œâ”€ Routing key: assessment.generated
   â””â”€ Payload: {material_id: "uuid", mongo_id: "507f..."}

3. api-mobile consume evento
   â”œâ”€ Crea registro en PostgreSQL.assessment
   â”œâ”€ Guarda: mongo_document_id = "507f..."
   â””â”€ material_id = "uuid"

4. Si PostgreSQL falla:
   â”œâ”€ Retry automÃ¡tico (3 intentos con backoff)
   â”œâ”€ Si sigue fallando â†’ Dead Letter Queue
   â””â”€ Operaciones puede reintentar manualmente
```

**Manejo de inconsistencias:**
```go
// api-mobile: GET /assessment/:id
func (s *Service) GetAssessment(ctx, id) (*Assessment, error) {
    // 1. Buscar en PostgreSQL
    pgRecord, err := s.pgRepo.Get(id)
    if err != nil {
        return nil, err
    }

    // 2. Validar que MongoDB existe
    mongoDoc, err := s.mongoRepo.Get(pgRecord.MongoDocumentID)
    if err != nil {
        // MongoDB doc no existe â†’ marcar como invÃ¡lido
        return nil, ErrAssessmentIncomplete
    }

    // 3. Combinar datos
    return merge(pgRecord, mongoDoc), nil
}
```

**ValidaciÃ³n diaria (cronjob):**
```sql
-- Encuentra orphan records en PostgreSQL
SELECT a.id, a.mongo_document_id
FROM assessment a
WHERE NOT EXISTS (
  SELECT 1 FROM mongodb.material_assessment
  WHERE _id::text = a.mongo_document_id
);
```

**âœ… Pros:**
- MongoDB es "fuente de verdad" para contenido (quizzes generados por IA)
- PostgreSQL es "Ã­ndice" para bÃºsquedas relacionales
- PatrÃ³n estÃ¡ndar en microservicios (eventual consistency)
- FÃ¡cil de implementar

**âŒ Contras:**
- Hay un pequeÃ±o perÃ­odo donde MongoDB tiene dato pero PostgreSQL no
- Requiere manejo de eventos (pero ya lo tienes con RabbitMQ)

**âš™ï¸ ImplementaciÃ³n:**
```
1. worker: Publicar evento assessment.generated despuÃ©s de Mongo
2. api-mobile: Consumer de evento para crear en PostgreSQL
3. Implementar retry logic (3 intentos)
4. Cronjob de validaciÃ³n (opcional)
5. Tiempo: 3-4 horas
```

**ğŸ¯ Impacto:**
- âœ… PatrÃ³n probado en producciÃ³n
- âœ… MongoDB es source of truth correcto
- âš ï¸ Requiere manejo de eventual consistency en UI

---

### OpciÃ³n 2: PostgreSQL primero + MongoDB despuÃ©s (Synchronous)

**CÃ³mo funciona:**
```
Flujo de creaciÃ³n:
1. Worker crea registro en PostgreSQL.assessment
   â”œâ”€ material_id: "uuid"
   â”œâ”€ mongo_document_id: NULL (por ahora)
   â”œâ”€ status: "processing"

2. Worker genera assessment en MongoDB
   â”œâ”€ _id: ObjectId("507f...")
   â”œâ”€ Contiene: {questions: [...]}

3. Worker actualiza PostgreSQL
   â”œâ”€ SET mongo_document_id = "507f..."
   â”œâ”€ SET status = "completed"

4. Si MongoDB falla:
   â”œâ”€ PostgreSQL queda con status = "processing"
   â”œâ”€ Retry automÃ¡tico
   â””â”€ UI muestra "Generando assessment..."
```

**Manejo de fallos:**
```go
func (w *Worker) ProcessMaterial(material) error {
    // 1. Crear placeholder en PostgreSQL
    assessment, _ := w.pgRepo.Create(&Assessment{
        MaterialID: material.ID,
        Status:     "processing",
    })

    // 2. Generar en MongoDB
    mongoDoc, err := w.aiService.GenerateQuiz(material)
    if err != nil {
        // MongoDB fallÃ³ â†’ marcar como failed
        w.pgRepo.Update(assessment.ID, "failed", "")
        return err
    }

    // 3. Actualizar PostgreSQL con referencia
    w.pgRepo.Update(assessment.ID, "completed", mongoDoc.ID)
    return nil
}
```

**âœ… Pros:**
- Estado siempre visible en PostgreSQL (processing/completed/failed)
- UI puede mostrar progreso en tiempo real
- FÃ¡cil de entender (flujo secuencial)

**âŒ Contras:**
- PostgreSQL tiene "basura" temporal (registros con status=processing)
- MÃ¡s transacciones (create + update en lugar de solo create)
- PostgreSQL no es source of truth de contenido

**âš™ï¸ ImplementaciÃ³n:**
```
1. worker: Crear en PostgreSQL primero
2. worker: Generar en MongoDB
3. worker: Update PostgreSQL con referencia
4. Agregar columna "status" a assessment
5. Tiempo: 3-4 horas
```

**ğŸ¯ Impacto:**
- âœ… UX mÃ¡s claro (progreso visible)
- âœ… Rollback mÃ¡s simple
- âš ï¸ Registros temporales en PostgreSQL

---

### OpciÃ³n 3: TransacciÃ³n distribuida (Saga Pattern)

**CÃ³mo funciona:**
```
Saga de creaciÃ³n de assessment:
1. Paso 1: Crear en MongoDB
   â””â”€ CompensaciÃ³n: Borrar de MongoDB

2. Paso 2: Crear en PostgreSQL
   â””â”€ CompensaciÃ³n: Borrar de PostgreSQL

Si Paso 2 falla:
â”œâ”€ Ejecutar compensaciÃ³n de Paso 1
â””â”€ Rollback completo (como si nunca pasÃ³)
```

**ImplementaciÃ³n con Saga library:**
```go
saga := saga.New()

saga.AddStep(
    // Forward
    func() error {
        mongoDoc, err := w.mongoRepo.Create(assessment)
        w.saga.Set("mongo_id", mongoDoc.ID)
        return err
    },
    // Compensate
    func() error {
        return w.mongoRepo.Delete(w.saga.Get("mongo_id"))
    },
)

saga.AddStep(
    // Forward
    func() error {
        return w.pgRepo.Create(&Assessment{
            MongoDocumentID: w.saga.Get("mongo_id"),
        })
    },
    // Compensate
    func() error {
        return w.pgRepo.Delete(assessment.ID)
    },
)

saga.Execute()
```

**âœ… Pros:**
- Consistencia fuerte (todo o nada)
- No hay datos inconsistentes
- PatrÃ³n enterprise-grade

**âŒ Contras:**
- Complejidad alta (Saga library o custom)
- Overhead de performance (compensaciones)
- Overkill para MVP

**âš™ï¸ ImplementaciÃ³n:**
```
1. Instalar saga library o implementar custom
2. Definir steps + compensations
3. Tests exhaustivos
4. Tiempo: 8-10 horas
```

**ğŸ¯ Impacto:**
- âœ… MÃ¡xima consistencia
- âŒ Complejidad excesiva para caso actual
- âš ï¸ Recomendado solo si es crÃ­tico de negocio

---

## ğŸ“ TU DECISIÃ“N

**OpciÃ³n elegida:** ____A_____ (Escribe: OpciÃ³n 1, OpciÃ³n 2, OpciÃ³n 3, u "Otra")

**Si eliges "Otra", describe tu soluciÃ³n:**
```
[Tu soluciÃ³n aquÃ­]
```

**RazÃ³n de tu decisiÃ³n:**
```
[Â¿Por quÃ© elegiste esta opciÃ³n?]
Sin tanto rollo, no sera la primera y ultima que queda datos basura, y prefiero mas mongo con esos datos huerfanos que pg, ya que pg es mas critico y es indice
```

**Estrategia de manejo de inconsistencias:**
```
[X] Eventual consistency (estÃ¡ OK si hay delay de segundos)
[ ] Strong consistency (DEBE ser consistente siempre)
[ ] Cronjob de reconciliaciÃ³n diario
[ ] Alertas cuando hay inconsistencias
[ ] Otra: __________
```

**Â¿QuÃ© base de datos es "fuente de verdad" del contenido?**
```
[X] MongoDB (tiene las preguntas/quizzes completos)
[ ] PostgreSQL (tiene metadata y relaciones)
[ ] Ambas son source of truth de su dominio
```

---

# ğŸ“‹ RESUMEN DE TUS DECISIONES

Una vez que completes las 4 sesiones, copia este resumen y envÃ­amelo:

```
DECISIONES TOMADAS:

1. Ownership de Tablas: [OpciÃ³n elegida]
   - api-admin crea: [tablas]
   - api-mobile crea: [tablas]

2. Contratos de Eventos: [OpciÃ³n elegida]
   - Eventos a documentar: [lista]
   - Versionamiento: [estrategia]

3. docker-compose.yml: [OpciÃ³n elegida]
   - Servicios incluidos: [lista]
   - Seeds necesarios: [lista]
   - Herramienta: [bash/make/otra]

4. SincronizaciÃ³n PG â†” Mongo: [OpciÃ³n elegida]
   - PatrÃ³n: [eventual/strong consistency]
   - Source of truth: [MongoDB/PostgreSQL/ambas]
```

---

# ğŸš€ PRÃ“XIMOS PASOS

DespuÃ©s de que completes tus decisiones:

1. **Guarda este archivo** con tus respuestas
2. **AvÃ­same** que terminaste
3. **Yo generarÃ©:**
   - âœ… Tareas especÃ­ficas basadas en tus decisiones
   - âœ… Archivos a crear con contenido exacto
   - âœ… Orden de ejecuciÃ³n optimizado
   - âœ… Tiempo estimado por tarea

**Tiempo total estimado para leer y decidir:** 30-45 minutos
**Tiempo total de implementaciÃ³n (despuÃ©s):** 10-18 horas (dependiendo de tus decisiones)

---

Â¡TÃ³mate tu tiempo para decidir! No hay respuestas incorrectas, solo trade-offs diferentes segÃºn tus prioridades (velocidad vs robustez, simplicidad vs escalabilidad, etc).
